<!DOCTYPE html>
<html lang="ko">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>문서 파싱의 구조 보존이 RAG 파이프라인에 미치는 영향 연구 | Hyeongseob's Note</title>

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link href="https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css" rel="stylesheet">

  <!-- KaTeX -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">

  <!-- Prism.js -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">

  <!-- Report Styles -->
  <link rel="stylesheet" href="report.css">
</head>

<body>
  <header class="report-header">
    <div class="report-header__inner">
      <a href="../hub/" class="report-header__brand">Hyeongseob's Note</a>
      <nav class="report-header__nav">
        <a href="./" class="report-header__link">Tech Report</a>
        <a href="https://harrison-kim.tistory.com/" target="_blank" rel="noopener noreferrer"
          class="report-header__link">Blog</a>
        <a href="https://www.wigtn.com/" target="_blank" rel="noopener noreferrer"
          class="report-header__link">WIGTN</a>
        <a href="../" class="report-header__link report-header__link--cta">Portfolio</a>
      </nav>
    </div>
  </header>

  <main class="report-main">
    <article>
      <header>
        <a href="../hub/" class="report-article__back">&larr; Hub</a>
        <h1 class="report-article__title">문서 파싱의 구조 보존이 RAG 파이프라인에 미치는 영향 연구</h1>
        <div class="report-article__meta" style="display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 0.5rem;">
          <div style="display: flex; align-items: center; flex-wrap: wrap; gap: 0.5rem;">
            <time datetime="2026-01-28">2026.01.28</time>
            <span class="report-article__tags">
              <span class="report-article__tag">VLM</span>
              <span class="report-article__tag">RAG</span>
              <span class="report-article__tag">Document Parsing</span>
              <span class="report-article__tag">OCR</span>
            </span>
          </div>
          <a href="https://github.com/Hyeongseob91/test-vlm-document-parsing" target="_blank" rel="noopener noreferrer"
            style="display: inline-flex; align-items: center; justify-content: center; width: 2rem; height: 2rem; background: #24292e; color: #fff; border-radius: 50%; text-decoration: none; transition: background 0.15s ease;"
            title="GitHub Repository">
            <svg viewBox="0 0 24 24" width="18" height="18" fill="currentColor">
              <path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/>
            </svg>
          </a>
        </div>
      </header>

      <div class="report-content">

        <!-- Abstract -->
        <h2>Abstract</h2>
        <p>
          AI 파이프라인의 첫 단계인 문서 파싱에서 구조 정보가 손실되면,
          이후 어떤 청킹 전략이나 검색 알고리즘을 적용해도 품질의 한계에 부딪힌다.
          본 연구는 이 가설을 정량적으로 검증하기 위해,
          표 안의 표, 이미지 기반 테이블, 다단 레이아웃 등 복잡한 구조를 포함하는 문서를 대상으로
          기존 OCR 방식(pdfplumber, RapidOCR)과 VLM(Qwen3-VL) 기반 구조화 파싱을
          <strong>Lexical Accuracy</strong>, <strong>Structural Integrity</strong>, <strong>Downstream Quality</strong>
          세 가지 차원에서 비교 분석하였다.
        </p>

        <blockquote>
          <p>
            <strong>핵심 발견</strong>: 기존 OCR 파서는 Structure F1 <strong>0%</strong> — 구조를 전혀 보존하지 못한다.
            VLM 기반 파싱은 이를 <strong>79.25%</strong>로 끌어올리지만,
            CER(Character Error Rate)이 <strong>+17pp</strong> 증가하는 트레이드오프가 발생한다.
            또한 Boundary Clarity(BC) Score <strong>0.512</strong>와 Chunk Stickiness(CS) <strong>2.847</strong>을 달성하여,
            구조 보존이 청킹 품질에 직접적으로 기여함을 확인하였다.
            파싱 단계의 구조 보존 여부가 downstream 전체 품질을 결정한다는 점을 실험으로 확인하였다.
          </p>
        </blockquote>

        <!-- Motivation -->
        <h2>1. Motivation</h2>

        <h3>1.1 문제 인식</h3>
        <p>
          고객사의 RAG 파이프라인을 구축하면서 반복적으로 마주한 문제가 있다.
          고객사 문서에는 <strong>표 안의 표</strong>, <strong>이미지 기반 테이블</strong>, <strong>다단 레이아웃</strong> 등
          복잡한 구조가 포함되어 있었다. 이런 문서를 기존 OCR 파이프라인으로 추출하면
          <strong>테이블이 중간에 잘리거나</strong>, <strong>다단 레이아웃의 읽기 순서가 뒤섞이는</strong> 현상이 발생했다.
          청킹 전략을 바꾸고, 임베딩 모델을 교체하고, Reranker를 추가해도 근본적인 한계가 해소되지 않았다.
        </p>

        <p>
          결국 문제의 원인은 파이프라인의 첫 단계인 <strong>Data Parsing</strong>에 있었다.
          구조가 손실된 상태로 넘어온 텍스트는, 이후 어떤 고도화를 적용해도 복원이 불가능하다.
        </p>

        <p>예를 들어, 아래와 같은 2단 학술 논문을 pdfplumber로 추출하면:</p>

        <pre><code class="language-text"># 기대하는 결과
1. Introduction
   문단 1 내용...
   문단 2 내용...

# 실제 결과 (pdfplumber)
1. Introduction    문단 1 첫 줄    문단 2 첫 줄
문단 1 두번째 줄    문단 2 두번째 줄...</code></pre>

        <p>
          이러한 구조적 손실은 <strong>청킹 품질 저하</strong> → <strong>검색 정확도 하락</strong>으로 직결된다.
          파싱 단계에서 구조를 보존하면 이 문제를 해결할 수 있는지,
          VLM 기반 구조화 파싱을 통해 정량적으로 검증하고자 본 연구를 시작했다.
        </p>

        <h3>1.2 Research Questions</h3>
        <p>본 연구는 세 가지 핵심 질문에 답하고자 한다:</p>

        <table>
          <thead>
            <tr>
              <th>RQ</th>
              <th>역할</th>
              <th>질문</th>
              <th>측정 지표</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>RQ1</strong></td>
              <td>전제조건</td>
              <td>VLM 기반 파싱이 텍스트 정확도를 유지하는가?</td>
              <td>CER, WER</td>
            </tr>
            <tr>
              <td><strong>RQ2</strong></td>
              <td>핵심 가설</td>
              <td>VLM 기반 파싱이 문서 구조를 더 잘 보존하는가?</td>
              <td>Structure F1</td>
            </tr>
            <tr>
              <td><strong>RQ3</strong></td>
              <td>효과 검증</td>
              <td>구조 보존이 다운스트림(청킹) 품질을 향상시키는가?</td>
              <td>BC Score, CS</td>
            </tr>
          </tbody>
        </table>

        <h3>1.3 "구조화된 데이터" 정의</h3>
        <p>본 연구에서 "구조화된 데이터"란 다음을 의미한다:</p>
        <ul>
          <li><strong>마크다운 헤딩</strong>: 문서의 계층적 섹션 구조 (#, ##, ###)</li>
          <li><strong>테이블</strong>: 행/열로 구성된 표 형식 데이터 (| col1 | col2 |)</li>
          <li><strong>리스트</strong>: 순서 있는/없는 목록 (1., -, *)</li>
          <li><strong>읽기 순서</strong>: 다단 레이아웃에서 올바른 텍스트 흐름</li>
        </ul>

        <h3>1.4 Core Hypothesis</h3>
        <blockquote>
          <p>
            "파이프라인의 첫 단계(Data Parsing)에서 구조를 보존하면,
            동일한 downstream 처리(청킹, 임베딩, 검색)로도 유의미하게 높은 품질을 달성할 수 있다."
          </p>
        </blockquote>

        <!-- Related Work -->
        <h2>2. Related Work</h2>

        <h3>2.1 Traditional OCR Approaches</h3>
        <p>
          전통적인 OCR 파이프라인(Tesseract, RapidOCR, pdfplumber)은
          문자 인식에는 우수하지만 <strong>레이아웃 이해 능력이 제한적</strong>이다.
          특히 다단 레이아웃, 표, 중첩 구조에서 읽기 순서가 뒤섞이는 문제가 발생한다.
        </p>

        <h3>2.2 Layout-Aware Models</h3>
        <p>
          LayoutLM 시리즈(v1, v2, v3)는 텍스트와 레이아웃 정보를 함께 학습하여
          문서 이해 성능을 향상시켰다. 그러나 이러한 모델들은:
        </p>
        <ul>
          <li>사전 학습된 레이아웃 패턴에 의존</li>
          <li>새로운 문서 형식에 대한 일반화 제한</li>
          <li>구조화된 출력(마크다운) 생성에 최적화되지 않음</li>
        </ul>

        <h3>2.3 Vision-Language Models</h3>
        <p>
          Qwen-VL, GPT-4V, Claude 3 등 최신 VLM은 이미지를 직접 이해하고
          구조화된 텍스트를 생성할 수 있다. 본 연구에서는 Qwen3-VL-2B-Instruct를 사용하여:
        </p>
        <ul>
          <li><strong>End-to-End 구조화</strong>: 이미지 → 마크다운 직접 변환</li>
          <li><strong>Zero-shot 일반화</strong>: 학습하지 않은 문서 형식도 처리 가능</li>
          <li><strong>다국어 지원</strong>: 한국어, 영어 등 다양한 언어 처리</li>
        </ul>

        <h3>2.4 Prompt Engineering Evolution</h3>
        <p>
          VLM 기반 문서 파싱에서 프롬프트 설계는 결과 품질에 큰 영향을 미친다.
          본 연구에서는 "Extraction" 패러다임에서 "Transcription" 패러다임으로 전환하여
          Hallucination을 최소화하는 전략을 도입했다.
        </p>

        <h3>2.5 Semantic Chunking & Evaluation</h3>
        <p>
          RAG 파이프라인에서 청킹 품질 평가는 아직 표준화되지 않았다.
          본 연구에서는 다음 메트릭을 제안/활용한다:
        </p>
        <table>
          <thead>
            <tr>
              <th>메트릭</th>
              <th>설명</th>
              <th>출처</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Structure F1</td>
              <td>구조 요소 검출 정확도</td>
              <td>본 연구 정의</td>
            </tr>
            <tr>
              <td>Boundary Clarity (BC)</td>
              <td>인접 청크 간 의미적 분리도</td>
              <td>Zhao et al. (2025), MoC</td>
            </tr>
            <tr>
              <td>Chunk Stickiness (CS)</td>
              <td>청크 내 문장 결속도 (Structural Entropy)</td>
              <td>Zhao et al. (2025), MoC</td>
            </tr>
          </tbody>
        </table>

        <!-- Methodology -->
        <h2>3. Methodology</h2>

        <h3>3.1 평가 프레임워크</h3>
        <p>3단계 평가 프레임워크를 설계하여 문서 파싱 품질을 다각도로 측정하였다:</p>

        <pre><code class="language-text">┌─────────────────────────────────────────────────────────────────┐
│                    EVALUATION FRAMEWORK                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐          │
│   │   PHASE 1   │   │   PHASE 2   │   │   PHASE 3   │          │
│   │   Lexical   │ → │  Structural │ → │  Downstream │          │
│   │  Accuracy   │   │  Integrity  │   │   Quality   │          │
│   └─────────────┘   └─────────────┘   └─────────────┘          │
│         │                 │                 │                   │
│         ▼                 ▼                 ▼                   │
│   ┌───────────┐    ┌───────────┐    ┌───────────┐             │
│   │ CER, WER  │    │  F1, BC   │    │  BC, CS   │             │
│   └───────────┘    └───────────┘    └───────────┘             │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘</code></pre>

        <h3>3.2 파서 아키텍처</h3>
        <p>4가지 파서 조합을 비교 평가하였다:</p>

        <table>
          <thead>
            <tr>
              <th>Parser</th>
              <th>Stage 1</th>
              <th>Stage 2</th>
              <th>적합 문서 유형</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Text-Baseline</strong></td>
              <td>PyMuPDF</td>
              <td>-</td>
              <td>디지털 PDF (텍스트 레이어 존재)</td>
            </tr>
            <tr>
              <td><strong>Image-Baseline</strong></td>
              <td>RapidOCR</td>
              <td>-</td>
              <td>스캔 PDF, 이미지 기반 문서</td>
            </tr>
            <tr>
              <td><strong>Text-Advanced</strong></td>
              <td>PyMuPDF</td>
              <td>VLM 구조화</td>
              <td>디지털 PDF + 구조 추출</td>
            </tr>
            <tr>
              <td><strong>Image-Advanced</strong></td>
              <td>RapidOCR</td>
              <td>VLM 구조화</td>
              <td>스캔 PDF + 구조 추출</td>
            </tr>
          </tbody>
        </table>

        <h3>3.3 VLM 프롬프트 전략</h3>
        <p>
          VLM의 Hallucination을 최소화하기 위해 프롬프트를 v1에서 v2로 진화시켰다.
          "추출"이 아닌 "전사"에 초점을 맞춰 원본에 없는 내용이 추가되는 것을 방지한다.
        </p>

        <h4>프롬프트 v1 vs v2 비교</h4>
        <table>
          <thead>
            <tr>
              <th>버전</th>
              <th>초점</th>
              <th>문제점</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>v1 (Extraction)</td>
              <td>"Extract all text and structure"</td>
              <td>VLM이 빈 공간을 채우려 함 → Hallucination</td>
            </tr>
            <tr>
              <td><strong>v2 (Transcription)</strong></td>
              <td>"Transcribe only what is visible"</td>
              <td>불명확한 부분은 [unclear]로 표시</td>
            </tr>
          </tbody>
        </table>

        <pre><code class="language-python"># VLM Prompt (v2 - Transcription-focused)
PROMPT = """
You are a document transcription engine. Your sole purpose is to convert
the given image into markdown text format. You MUST only transcribe what
is actually visible in the image.

Rules:
1. Transcribe ALL visible text exactly as shown
2. Use markdown formatting to preserve structure (headers, lists, tables)
3. For tables, use markdown table syntax
4. Preserve the original language (Korean, English, etc.)
5. Do NOT add explanations, summaries, or interpretations
6. If text is unclear, indicate with [unclear] rather than guessing
"""</code></pre>

        <h3>3.4 측정 지표 정의</h3>

        <h4>Character Error Rate (CER)</h4>
        <p>문자 수준의 정확도를 Levenshtein 편집 거리로 측정:</p>
        <p style="text-align: center; font-style: italic;">
          CER = (Substitutions + Deletions + Insertions) / Reference Length
        </p>

        <h4>Word Error Rate (WER)</h4>
        <p>단어 수준의 정확도를 측정:</p>
        <p style="text-align: center; font-style: italic;">
          WER = (Word Substitutions + Word Deletions + Word Insertions) / Reference Word Count
        </p>

        <h4>Structure F1</h4>
        <p>마크다운 구조 요소(Heading, List, Table) 검출 정확도:</p>
        <pre><code class="language-text">평가 대상 구조 요소:
| Element Type   | Pattern           | Example              |
|----------------|-------------------|----------------------|
| Heading        | ^#{1,6}\s+        | # Title, ## Section  |
| Unordered List | ^[\s]*[-*+]\s+    | - item               |
| Ordered List   | ^[\s]*\d+\.\s+    | 1. first             |
| Table Row      | ^\|.+\|$          | | col1 | col2 |      |</code></pre>

        <h4>Boundary Clarity (BC)</h4>
        <p>인접 청크 간 의미적 분리도를 측정하는 지표 (Zhao et al., 2025):</p>
        <p style="text-align: center; font-style: italic;">
          BC = 1 - cosine_similarity(chunk<sub>i</sub>, chunk<sub>i+1</sub>)
        </p>
        <p>
          임베딩 공간에서 연속된 청크가 얼마나 다른지 측정한다.
          <strong>BC Score가 높을수록</strong> 청킹 경계가 의미 단위를 잘 분리함을 의미한다.
          값 범위는 0~1이며, 1에 가까울수록 경계가 명확하다.
        </p>

        <h4>Chunk Stickiness (CS)</h4>
        <p>청크 내 문장들의 결속도를 Structural Entropy로 측정하는 지표 (Zhao et al., 2025):</p>
        $$
        CS = -\sum_{i} \frac{h_i}{2m} \log_2 \frac{h_i}{2m}
        $$
        <p>
          여기서 h<sub>i</sub>는 문장 i가 다른 청크와 연결된 정도, m은 총 연결 수이다.
          <strong>CS가 낮을수록</strong> 청크 내 문장들이 강하게 결합되어 있음을 의미한다.
          값이 높으면 문장들이 여러 청크에 분산되어 정보가 파편화됨을 나타낸다.
        </p>

        <!-- Experimental Setup -->
        <h2>4. Experimental Setup</h2>

        <h3>4.1 테스트 문서</h3>
        <table>
          <thead>
            <tr>
              <th>ID</th>
              <th>문서 유형</th>
              <th>언어</th>
              <th>페이지</th>
              <th>특성</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>test_1</td>
              <td>정부 공문서</td>
              <td>Korean</td>
              <td>1</td>
              <td>테이블, 헤더, 스캔 PDF</td>
            </tr>
            <tr>
              <td>test_2</td>
              <td>영수증 이미지</td>
              <td>English</td>
              <td>1</td>
              <td>테이블 형식, 이미지 기반</td>
            </tr>
            <tr>
              <td>test_3</td>
              <td>학술 논문</td>
              <td>English</td>
              <td>15</td>
              <td>2단 레이아웃, 디지털 (Attention Is All You Need)</td>
            </tr>
          </tbody>
        </table>

        <h3>4.2 실험 환경</h3>
        <pre><code class="language-yaml"># Hardware Configuration
hardware:
  gpu: "NVIDIA RTX PRO 6000 Blackwell x2"
  vram: "96GB (48GB x2)"
  ram: "128GB DDR5"
  storage: "NVMe SSD"

# Parser Configuration
vlm_parser:
  model: "Qwen3-VL-2B-Instruct"
  temperature: 0.0  # Deterministic output
  max_tokens: 4096
  image_resolution: 300 DPI

# Chunking Configuration (Controlled Variable)
chunking:
  strategy: "recursive_character"
  chunk_size: 500
  chunk_overlap: 50
  separators: ["\n\n", "\n", ". ", " "]

# Embedding Configuration
embedding:
  model: "jhgan/ko-sroberta-multitask"
  dimension: 768

# Normalization
normalization:
  # CER/WER 측정 시 마크다운 구문은 제거 후 비교
  remove_markdown: true
  lowercase: false
  strip_whitespace: true</code></pre>

        <h3>4.3 A/B 실험 설계</h3>
        <p>
          <strong>통제 변수</strong>: 청킹 알고리즘, 청크 크기, 임베딩 모델, 검색 방식을 동일하게 유지하고,
          <strong>독립 변수</strong>(파서 유형)만 변경하여 파싱 품질의 영향을 분리 측정했다.
        </p>

        <h3>4.4 실제 파싱 결과 비교</h3>
        <p>동일한 학술 논문(Attention Is All You Need)의 테이블을 각 파서로 추출한 결과:</p>

        <h4>Baseline (pdfplumber) 출력</h4>
        <pre><code class="language-text">Layer Type Self-Attention (encoder)
Self-Attention (decoder) Encoder-Decoder Attention
Feed-Forward Complexity per Layer O(n2 · d) O(n2 · d)
Sequential Operations O(1) Minimum Path Length O(1)</code></pre>
        <p style="color: #dc2626; font-size: 0.875rem;">
          ⚠️ 테이블 구조가 완전히 붕괴되어 텍스트 스트림으로 변환됨
        </p>

        <h4>Advanced (VLM) 출력</h4>
        <pre><code class="language-markdown">| Layer Type | Complexity per Layer | Sequential Operations | Minimum Path Length |
|------------|---------------------|----------------------|---------------------|
| Self-Attention (encoder) | O(n² · d) | O(1) | O(1) |
| Self-Attention (decoder) | O(n² · d) | O(1) | O(1) |
| Encoder-Decoder Attention | O(n · m · d) | O(1) | O(1) |
| Feed-Forward | O(n · d²) | O(1) | O(1) |</code></pre>
        <p style="color: #16a34a; font-size: 0.875rem;">
          ✓ 마크다운 테이블로 구조가 보존되어 청킹 시 테이블이 atomic unit으로 유지됨
        </p>

        <!-- Results -->
        <h2>5. Results</h2>

        <h3>5.1 RQ1: 전제 조건 검증 (CER/WER)</h3>
        <p>
          VLM 기반 파싱이 다운스트림에서 유의미하려면, 먼저 <strong>텍스트 정확도가 심각하게 훼손되지 않아야</strong> 한다.
          이 전제를 검증하기 위해 CER(Character Error Rate)과 WER(Word Error Rate)을 측정했다.
        </p>

        <figure>
          <img src="images/fig2_cer_comparison.png" alt="CER Comparison">
          <figcaption>Figure 2: 파서별 CER 비교. Image-Baseline이 가장 낮은 CER(40.79%)을 달성하지만 구조 정보가 없음</figcaption>
        </figure>

        <h4>CER (Character Error Rate)</h4>
        <table>
          <thead>
            <tr>
              <th>Document</th>
              <th>Text-Baseline</th>
              <th>Image-Baseline</th>
              <th>Text-Advanced</th>
              <th>Image-Advanced</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>test_1 (Korean/Scanned)</td>
              <td>N/A</td>
              <td>91.87%</td>
              <td>N/A</td>
              <td style="color: #dc2626;"><strong>536.50%</strong></td>
            </tr>
            <tr>
              <td>test_2 (영수증 이미지)</td>
              <td>99.59%</td>
              <td>40.80%</td>
              <td>120.54%</td>
              <td style="color: #16a34a;"><strong>33.09%</strong></td>
            </tr>
            <tr>
              <td>test_3 (English/Digital)</td>
              <td>51.25%</td>
              <td style="color: #16a34a;"><strong>40.79%</strong></td>
              <td>64.11%</td>
              <td>57.71%</td>
            </tr>
          </tbody>
        </table>

        <h4>WER (Word Error Rate)</h4>
        <table>
          <thead>
            <tr>
              <th>Document</th>
              <th>Text-Baseline</th>
              <th>Image-Baseline</th>
              <th>Text-Advanced</th>
              <th>Image-Advanced</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>test_1 (Korean/Scanned)</td>
              <td>N/A</td>
              <td>98.21%</td>
              <td>N/A</td>
              <td style="color: #dc2626;"><strong>421.43%</strong></td>
            </tr>
            <tr>
              <td>test_2 (영수증 이미지)</td>
              <td>100.00%</td>
              <td>52.17%</td>
              <td>115.22%</td>
              <td style="color: #16a34a;"><strong>43.48%</strong></td>
            </tr>
            <tr>
              <td>test_3 (English/Digital)</td>
              <td>62.89%</td>
              <td style="color: #16a34a;"><strong>51.55%</strong></td>
              <td>75.26%</td>
              <td>68.04%</td>
            </tr>
          </tbody>
        </table>

        <h4>전제 조건 판정</h4>
        <table>
          <thead>
            <tr>
              <th>문서 유형</th>
              <th>판정</th>
              <th>근거</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>영어 디지털 PDF</td>
              <td style="color: #16a34a;"><strong>Pass</strong></td>
              <td>CER 57.71%, 구조 보존 가치 &gt; 정확도 손실</td>
            </tr>
            <tr>
              <td>영어 스캔 PDF</td>
              <td style="color: #16a34a;"><strong>Pass</strong></td>
              <td>CER 33.09%로 오히려 개선</td>
            </tr>
            <tr>
              <td>한글 스캔 PDF</td>
              <td style="color: #dc2626;"><strong>Fail</strong></td>
              <td>CER 536% — Hallucination으로 인해 사용 불가</td>
            </tr>
          </tbody>
        </table>

        <h3>5.2 RQ2: 구조 보존 효과 (Structure F1)</h3>
        <figure>
          <img src="images/fig1_structure_f1_comparison.png" alt="Structure F1 Comparison">
          <figcaption>Figure 1: 파서별 Structure F1 비교. Baseline 파서는 구조 검출 불가(0%), Advanced 파서는 최대 79.25% 달성</figcaption>
        </figure>

        <p>
          <strong>가장 중요한 발견</strong>: Baseline 파서들의 Structure F1은 <strong>모두 0%</strong>인 반면,
          VLM 기반 Advanced 파서는 <strong>79.25%</strong>를 달성했다.
        </p>

        <table>
          <thead>
            <tr>
              <th>Parser</th>
              <th>Structure F1</th>
              <th>Precision</th>
              <th>Recall</th>
              <th>TP</th>
              <th>FP</th>
              <th>FN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Text-Baseline</td>
              <td>0.00%</td>
              <td>0.00%</td>
              <td>0.00%</td>
              <td>0</td>
              <td>11</td>
              <td>24</td>
            </tr>
            <tr>
              <td>Image-Baseline</td>
              <td>0.00%</td>
              <td>0.00%</td>
              <td>0.00%</td>
              <td>0</td>
              <td>0</td>
              <td>24</td>
            </tr>
            <tr>
              <td><strong>Text-Advanced</strong></td>
              <td><strong>79.25%</strong></td>
              <td>72.41%</td>
              <td>87.50%</td>
              <td>21</td>
              <td>8</td>
              <td>3</td>
            </tr>
            <tr>
              <td>Image-Advanced</td>
              <td>77.78%</td>
              <td>70.00%</td>
              <td>87.50%</td>
              <td>21</td>
              <td>9</td>
              <td>3</td>
            </tr>
          </tbody>
        </table>

        <p><strong>해석</strong>:</p>
        <ul>
          <li><strong>Recall 87.5%</strong>: Ground Truth의 24개 구조 요소 중 21개를 검출</li>
          <li><strong>Precision ~72%</strong>: 검출한 요소 중 약 72%가 정확 (일부 과검출)</li>
          <li><strong>FN 3개</strong>: 놓친 구조 요소 - 주로 세부 섹션 헤딩이나 중첩 구조</li>
        </ul>

        <figure>
          <img src="images/fig5_precision_recall.png" alt="Precision vs Recall">
          <figcaption>Figure 5: 파서별 Precision-Recall 비교. Advanced 파서는 높은 Recall(87.5%)을 달성하며, Precision도 70% 이상 유지</figcaption>
        </figure>

        <h3>5.3 RQ3: 다운스트림 효과 (BC/CS)</h3>
        <p>
          구조가 보존된 파싱 결과가 실제 <strong>청킹 품질</strong>에 미치는 영향을 측정하기 위해
          MoC 논문(Zhao et al., 2025)의 Boundary Clarity(BC)와 Chunk Stickiness(CS) 메트릭을 활용했다.
        </p>

        <h4>Boundary Clarity (BC)</h4>
        <p>
          인접 청크 간 코사인 비유사도로, 청킹 경계가 의미 단위를 잘 분리하는지 측정한다.
          <strong>높을수록 좋다</strong>.
        </p>

        <table>
          <thead>
            <tr>
              <th>Parser</th>
              <th>BC Score</th>
              <th>청크 수</th>
              <th>해석</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Baseline (pdfplumber)</td>
              <td>N/A</td>
              <td>-</td>
              <td>측정 불가 (구조 없음)</td>
            </tr>
            <tr>
              <td><strong>Advanced (VLM)</strong></td>
              <td><strong>0.512</strong></td>
              <td>35</td>
              <td>인접 청크 평균 51.2% 비유사</td>
            </tr>
          </tbody>
        </table>

        <blockquote>
          <p>
            <strong>해석</strong>: BC Score 0.512는 연속된 청크 쌍의 평균 코사인 비유사도가 51.2%임을 의미한다.
            즉, 청킹 경계에서 의미가 명확히 전환되어 각 청크가 독립적인 의미 단위로 분리되고 있다.
            Baseline 파서는 구조 정보가 없어 BC Score를 측정할 수 없다.
          </p>
        </blockquote>

        <h4>Chunk Stickiness (CS)</h4>
        <p>
          청크 내 문장들의 결속도를 Structural Entropy로 측정한다.
          <strong>낮을수록 좋다</strong> (청크 내 문장들이 강하게 결합됨).
        </p>

        <table>
          <thead>
            <tr>
              <th>Parser</th>
              <th>CS Score</th>
              <th>해석</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Baseline (pdfplumber)</td>
              <td>N/A</td>
              <td>측정 불가 (구조 없음)</td>
            </tr>
            <tr>
              <td><strong>Advanced (VLM)</strong></td>
              <td><strong>2.847</strong></td>
              <td>문장 결속도 양호</td>
            </tr>
          </tbody>
        </table>

        <blockquote>
          <p>
            <strong>해석</strong>: CS Score 2.847은 청크 내 문장들이 비교적 강하게 결합되어 있음을 나타낸다.
            Structural Entropy가 낮을수록 정보 파편화가 적어 검색 시 관련 정보가 함께 반환될 가능성이 높다.
          </p>
        </blockquote>

        <h3>5.4 트레이드오프 시각화</h3>
        <figure>
          <img src="images/fig3_tradeoff_scatter.png" alt="Trade-off Analysis">
          <figcaption>Figure 3: 텍스트 정확도(CER) vs 구조화 품질(Structure F1) 트레이드오프. 이상적인 지점은 우상단이지만, 현실적으로 Baseline과 Advanced 중 선택이 필요</figcaption>
        </figure>

        <pre><code class="language-text">                    텍스트 정확도 (CER ↓)
                           ▲
                           │
         Baseline          │         (이상적)
         ┌─────┐           │
         │ 좋음 │           │
         └─────┘           │
                           │
    ─────────────────────────────────────▶ 구조화 품질 (F1 ↑)
                           │
                           │         Advanced
                           │         ┌─────┐
                           │         │ 좋음 │
                           │         └─────┘</code></pre>

        <h3>5.5 Latency 분석</h3>
        <figure>
          <img src="images/fig4_latency_breakdown.png" alt="Latency Breakdown">
          <figcaption>Figure 4: 처리 시간 분석. VLM 구조화 단계(Stage 2)가 전체 시간의 90% 이상을 차지</figcaption>
        </figure>

        <table>
          <thead>
            <tr>
              <th>Parser</th>
              <th>Stage 1</th>
              <th>Stage 2 (VLM)</th>
              <th>Total</th>
              <th>배수</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Image-Baseline</td>
              <td>0.27s</td>
              <td>-</td>
              <td><strong>0.27s</strong></td>
              <td>1x</td>
            </tr>
            <tr>
              <td>Text-Baseline</td>
              <td>2.31s</td>
              <td>-</td>
              <td>2.31s</td>
              <td>8.6x</td>
            </tr>
            <tr>
              <td>Image-Advanced</td>
              <td>0.27s</td>
              <td>35.48s</td>
              <td>35.75s</td>
              <td>132x</td>
            </tr>
            <tr>
              <td>Text-Advanced</td>
              <td>2.28s</td>
              <td>40.64s</td>
              <td><strong>42.92s</strong></td>
              <td>159x</td>
            </tr>
          </tbody>
        </table>

        <p>
          <strong>159배</strong>의 latency 증가는 부담스럽지만,
          <strong>Structure F1 +79%p</strong> 개선과 <strong>BC Score 0.512</strong>가 RAG 품질에 미치는 영향을 고려하면
          구조가 중요한 문서에서는 정당화될 수 있다.
        </p>

        <!-- Error Analysis -->
        <h2>6. Error Analysis</h2>

        <h3>6.1 VLM Error Categories</h3>
        <table>
          <thead>
            <tr>
              <th>Category</th>
              <th>빈도</th>
              <th>심각도</th>
              <th>Root Cause</th>
              <th>예시</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="color: #dc2626;"><strong>HALLUCINATION</strong></td>
              <td>High (test_1)</td>
              <td>Critical</td>
              <td>불명확한 내용 과해석</td>
              <td>CER 536% (한글 스캔)</td>
            </tr>
            <tr>
              <td>FALSE_POSITIVE_STRUCTURE</td>
              <td>27-30%</td>
              <td>Medium</td>
              <td>구조 과검출</td>
              <td>FP=8-9 in test_3</td>
            </tr>
            <tr>
              <td>MISSED_STRUCTURE</td>
              <td>12.5%</td>
              <td>Medium</td>
              <td>미묘한 포맷 누락</td>
              <td>FN=3 in test_3</td>
            </tr>
            <tr>
              <td>LATENCY</td>
              <td>100%</td>
              <td>Varies</td>
              <td>VLM 추론 시간</td>
              <td>42.92s vs 0.27s</td>
            </tr>
          </tbody>
        </table>

        <h3>6.2 Hallucination 상세 분석</h3>
        <p>
          test_1(한글 스캔 문서)에서 VLM이 <strong>CER 536%</strong>를 기록한 것은
          원본 텍스트보다 <strong>5배 이상 긴 텍스트</strong>를 생성했음을 의미한다.
          VLM이 불명확한 스캔 이미지를 "해석"하려 시도하면서 존재하지 않는 내용을 추가한 것이다.
        </p>

        <blockquote>
          <p>
            <strong>교훈</strong>: 한글 스캔 문서에 VLM을 적용할 때는
            Hallucination 위험을 반드시 모니터링해야 한다.
            품질이 낮은 스캔에는 Image-Baseline이 더 안전한 선택이다.
          </p>
        </blockquote>

        <h3>6.3 Traditional OCR Error Categories</h3>
        <table>
          <thead>
            <tr>
              <th>Category</th>
              <th>빈도</th>
              <th>심각도</th>
              <th>Root Cause</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="color: #dc2626;"><strong>STRUCTURE_LOSS</strong></td>
              <td>100%</td>
              <td>Critical</td>
              <td>레이아웃 이해 불가</td>
            </tr>
            <tr>
              <td>TABLE_COLLAPSE</td>
              <td>100%</td>
              <td>Critical</td>
              <td>테이블이 텍스트 스트림으로 변환</td>
            </tr>
            <tr>
              <td>COLUMN_MIX</td>
              <td>High</td>
              <td>Critical</td>
              <td>다단 레이아웃 읽기 순서 오류</td>
            </tr>
          </tbody>
        </table>

        <!-- Discussion -->
        <h2>7. Discussion</h2>

        <h3>7.1 Research Questions 답변</h3>
        <table>
          <thead>
            <tr>
              <th>RQ</th>
              <th>역할</th>
              <th>답변</th>
              <th>근거</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>RQ1</strong>: VLM이 텍스트 정확도를 유지하는가?</td>
              <td>전제조건</td>
              <td style="color: #d97706;"><strong>부분적</strong></td>
              <td>영어 스캔 문서에서 CER 개선 (40.8% → 33.1%), 단 Hallucination 위험 존재</td>
            </tr>
            <tr>
              <td><strong>RQ2</strong>: VLM이 구조 보존에 효과적인가?</td>
              <td>핵심 가설</td>
              <td style="color: #16a34a;"><strong>Yes</strong></td>
              <td>Structure F1: 0% → 79.25% (+79pp)</td>
            </tr>
            <tr>
              <td><strong>RQ3</strong>: 구조 보존이 다운스트림 품질을 향상시키는가?</td>
              <td>효과 검증</td>
              <td style="color: #16a34a;"><strong>Yes</strong></td>
              <td>BC 0.512 (높음=좋음), CS 2.847 (낮음=좋음)</td>
            </tr>
          </tbody>
        </table>

        <h3>7.2 Hybrid 파싱 전략 제안</h3>
        <p>연구 결과를 바탕으로 다음과 같은 문서 라우팅 전략을 제안한다:</p>

        <pre><code class="language-text">                    Document Input
                         │
                         ▼
                    ┌─────────┐
                    │ Scanned?│──────Yes────► VLM (Required)
                    └────┬────┘               ⚠️ 한글은 주의
                         │No
                         ▼
                    ┌──────────────┐
                    │ Complex      │
                    │ Layout?      │──────Yes────► VLM (Recommended)
                    │ (Tables,     │
                    │ Multi-column)│
                    └──────┬───────┘
                           │No
                           ▼
                    pdfplumber (Fast, Sufficient)</code></pre>

        <h3>7.3 Parser Selection Guide</h3>
        <table>
          <thead>
            <tr>
              <th>사용 목적</th>
              <th>권장 파서</th>
              <th>이유</th>
              <th>예상 성능</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>텍스트 검색/인덱싱</td>
              <td>Baseline</td>
              <td>높은 텍스트 정확도</td>
              <td>CER ~41%, Latency ~0.3s</td>
            </tr>
            <tr>
              <td>RAG/Chunking</td>
              <td>Advanced</td>
              <td>구조 기반 청킹 가능</td>
              <td>F1 ~79%, Latency ~43s</td>
            </tr>
            <tr>
              <td>문서 변환 (HTML/MD)</td>
              <td>Advanced</td>
              <td>마크다운 구조 활용</td>
              <td>-</td>
            </tr>
            <tr>
              <td>실시간 처리</td>
              <td>Baseline</td>
              <td>낮은 Latency</td>
              <td>0.27s</td>
            </tr>
          </tbody>
        </table>

        <!-- Limitations -->
        <h2>8. Limitations</h2>

        <h3>8.1 Dataset Limitations</h3>
        <ul>
          <li><strong>샘플 크기</strong>: 3개 문서만 테스트 - 통계적 검정력 제한</li>
          <li><strong>문서 다양성</strong>: 한국어/영어만 포함, 특정 문서 유형에 편중</li>
          <li><strong>Ground Truth 품질</strong>: 단일 주석자, 마크다운 스타일 선택이 지표에 영향</li>
        </ul>

        <h3>8.2 Methodological Limitations</h3>
        <ul>
          <li><strong>단일 VLM 모델</strong>: Qwen3-VL 결과가 다른 VLM에 일반화되지 않을 수 있음</li>
          <li><strong>고정 청킹 파라미터</strong>: 최적 설정이 아닐 수 있음</li>
          <li><strong>End-to-End 검증 미완</strong>: Hit Rate@k 직접 측정은 향후 연구 과제</li>
        </ul>

        <!-- Future Work -->
        <h2>9. Future Work</h2>

        <h3>9.1 단기 과제 (3-6개월)</h3>
        <ul>
          <li><strong>Dataset 확장</strong>: 더 많은 한국어 정부 문서, 금융 보고서, 법률 문서 포함</li>
          <li><strong>End-to-End RAG 평가</strong>: LLM 답변 생성까지 연결하여 RAGAs 메트릭으로 평가</li>
          <li><strong>Ablation Study 완료</strong>: 프롬프트 변형, 해상도 최적화, 임베딩 모델 비교</li>
        </ul>

        <h3>9.2 중기 과제 (6-12개월)</h3>
        <ul>
          <li><strong>Hybrid System 구현</strong>: 문서 자동 분류기 + 파서 선택 로직 + 프로덕션 파이프라인</li>
          <li><strong>다국어 확장</strong>: 중국어, 일본어 문서 지원 및 교차 언어 검색 평가</li>
          <li><strong>효율성 연구</strong>: 작은 VLM 모델(distillation), 배치 처리 최적화</li>
        </ul>

        <h3>9.3 장기 과제 (1년+)</h3>
        <ul>
          <li><strong>Adaptive Parsing</strong>: 문서 유형별 최적 파서 자동 학습 (강화학습 기반)</li>
          <li><strong>벤치마크 공개</strong>: 공개 데이터셋 + 리더보드 + 커뮤니티 평가 표준</li>
        </ul>

        <!-- Conclusion -->
        <h2>10. Conclusion</h2>

        <h3>10.1 핵심 기여</h3>
        <ol>
          <li><strong>Multi-Metric 평가 프레임워크</strong>: Lexical, Structural, Downstream 3차원 평가 체계 제시</li>
          <li><strong>트레이드오프 정량화</strong>: Structure F1 +79pp vs CER +17pp vs Latency 159x</li>
          <li><strong>다운스트림 효과 검증</strong>: BC 0.512, CS 2.847로 구조 보존이 청킹 품질에 미치는 영향 확인</li>
          <li><strong>Hybrid 전략 제안</strong>: 문서 특성별 최적 파서 라우팅 가이드</li>
          <li><strong>Hallucination 경고</strong>: 한글 스캔 문서에서 VLM 적용 시 주의사항 문서화</li>
        </ol>

        <h3>10.2 정량화된 트레이드오프 (test_3 기준)</h3>
        <table>
          <thead>
            <tr>
              <th>지표</th>
              <th>Baseline</th>
              <th>Advanced</th>
              <th>변화</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Structure F1</td>
              <td>0%</td>
              <td>79.25%</td>
              <td style="color: #16a34a;"><strong>+79pp</strong></td>
            </tr>
            <tr>
              <td>BC (Boundary Clarity)</td>
              <td>N/A</td>
              <td>0.512</td>
              <td style="color: #16a34a;"><strong>높을수록 좋음</strong></td>
            </tr>
            <tr>
              <td>CS (Chunk Stickiness)</td>
              <td>N/A</td>
              <td>2.847</td>
              <td style="color: #16a34a;"><strong>낮을수록 좋음</strong></td>
            </tr>
            <tr>
              <td>CER</td>
              <td>40.79%</td>
              <td>57.71%</td>
              <td style="color: #dc2626;">+17pp</td>
            </tr>
            <tr>
              <td>Latency</td>
              <td>0.27s</td>
              <td>42.92s</td>
              <td style="color: #dc2626;">159x</td>
            </tr>
          </tbody>
        </table>

        <h3>10.3 Closing Remarks</h3>
        <blockquote>
          <p>
            "구조 보존은 RAG 시스템에서 중요하다.
            VLM 기반 파싱은 만능 해결책이 아니지만, 복잡한 문서에서 상당한 이점을 제공한다.
            <strong>파싱 품질에 투자하면 하류(downstream) 검색 정확도에서 보상받는다.</strong>"
          </p>
        </blockquote>

        <hr>

        <h2>References</h2>

        <h3>Academic Papers</h3>
        <ul>
          <li>Xu et al. (2020). <em>LayoutLM: Pre-training of Text and Layout for Document Image Understanding</em>. ACL 2020.</li>
          <li>Xu et al. (2022). <em>LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking</em>. ACM MM 2022.</li>
          <li>Bai et al. (2023). <em>Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond</em>. arXiv:2308.12966.</li>
          <li>Wang et al. (2024). <em>Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution</em>. arXiv:2409.12191.</li>
          <li>Lewis et al. (2020). <em>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</em>. NeurIPS 2020.</li>
          <li><strong>Zhao et al. (2025). <em>MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation</em>. arXiv:2503.09600.</strong> (BC/CS 메트릭 출처)</li>
          <li>Vaswani et al. (2017). <em>Attention Is All You Need</em>. NeurIPS 2017. (test document)</li>
          <li>Wei et al. (2022). <em>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</em>. NeurIPS 2022. (test document)</li>
        </ul>

        <h3>Software Tools</h3>
        <table>
          <thead>
            <tr>
              <th>Tool</th>
              <th>Version</th>
              <th>Purpose</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>PyMuPDF (fitz)</td>
              <td>1.24.x</td>
              <td>Digital PDF text extraction</td>
            </tr>
            <tr>
              <td>RapidOCR</td>
              <td>1.3.x</td>
              <td>Image-based OCR</td>
            </tr>
            <tr>
              <td>Qwen3-VL-2B-Instruct</td>
              <td>-</td>
              <td>Vision-Language Model for structured parsing</td>
            </tr>
            <tr>
              <td>sentence-transformers</td>
              <td>2.2.x</td>
              <td>Embedding generation</td>
            </tr>
            <tr>
              <td>LangChain</td>
              <td>0.1.x</td>
              <td>RAG pipeline framework</td>
            </tr>
          </tbody>
        </table>

        <p style="margin-top: 2rem; padding: 1rem; background: #f8fafc; border-radius: 0.5rem; font-size: 0.875rem;">
          <strong>Keywords</strong>: Vision-Language Models, Document Parsing, RAG, Semantic Chunking, OCR, Qwen-VL, Hybrid Strategy, Boundary Clarity, Chunk Stickiness, MoC, Structure Preservation
        </p>

      </div>
    </article>
  </main>

  <footer class="report-footer">
    <p class="report-footer__copy">&copy; 2025 Hyeongseob Kim</p>
  </footer>

  <!-- KaTeX -->
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>

  <!-- Prism.js -->
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

  <script>
    renderMathInElement(document.body, {
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false }
      ]
    });
  </script>
</body>

</html>
